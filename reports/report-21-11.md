# üìÑ RELAT√ìRIO ‚Äî Entrega 21/11
## Projeto Final ‚Äî IF1015 (T√≥picos Avan√ßados em SI 6)
### Treinamento Parcial ‚Äì Classifica√ß√£o de Toxicidade com BERT

---

# 1. Introdu√ß√£o

Este projeto tem como objetivo aplicar t√©cnicas de Aprendizagem Profunda em uma tarefa de Processamento de Linguagem Natural (PLN), especificamente na classifica√ß√£o de toxicidade em coment√°rios online.  

Esta √© a primeira entrega do projeto, englobando:

- defini√ß√£o da aplica√ß√£o,  
- sele√ß√£o do dataset,  
- prepara√ß√£o dos dados,  
- implementa√ß√£o do modelo,  
- e apresenta√ß√£o dos primeiros resultados parciais de treinamento.

---

# 2. Defini√ß√£o da Aplica√ß√£o

### Tarefa  
Classifica√ß√£o multi-r√≥tulo (multi-label) de toxicidade em textos.

### Objetivo  
Dado um coment√°rio, prever pontua√ß√µes para seis tipos de toxicidade:

- toxic  
- severe_toxic  
- obscene  
- threat  
- insult  
- identity_hate  

### Justificativa  
A detec√ß√£o autom√°tica de conte√∫do t√≥xico √© fundamental para modera√ß√£o de plataformas, seguran√ßa e prote√ß√£o de usu√°rios.  

Al√©m disso, essa tarefa √© adequada para estudos de:

- robustez de modelos de PLN,  
- interpretabilidade,  
- e ataques advers√°rios,  

que ser√£o abordados nas pr√≥ximas entregas.

---

# 3. Dataset

### Nome  
Jigsaw Toxic Comment Classification Challenge (Kaggle)

### Descri√ß√£o  
Dataset composto por coment√°rios do Wikipedia Talk Page, rotulados em seis categorias de toxicidade.

### Formato  
Arquivo CSV contendo:

- id  
- comment_text  
- seis r√≥tulos bin√°rios (0/1)

### Tamanho original  
159.571 exemplos rotulados.

### Subset utilizado nesta etapa  
Para acelerar o treinamento no MacBook Air M4 (GPU MPS):

- **20.000** exemplos de treino  
- **2.000** exemplos de valida√ß√£o

### Observa√ß√£o  
Foi criada uma coluna `labels` contendo o vetor `[toxic, severe_toxic, obscene, threat, insult, identity_hate]`, necess√°ria para a classifica√ß√£o multi-label.

---

# 4. Modelo Utilizado

### Arquitetura  
BERT Base ‚Äî `bert-base-uncased`

### Framework  
HuggingFace Transformers + PyTorch

### Configura√ß√£o  
- Cabe√ßa de sa√≠da com 6 neur√¥nios  
- fun√ß√£o de ativa√ß√£o sigmoid  
- perda BCEWithLogitsLoss  
- configura√ß√£o `problem_type="multi_label_classification"`

### Motivos da escolha  
- forte desempenho em tarefas de classifica√ß√£o textual,  
- robustez,  
- facilidade de an√°lise de interpretabilidade,  
- adequa√ß√£o para estudos adversariais.

---

# 5. Pr√©-processamento e Tokeniza√ß√£o

### Tokeniza√ß√£o
- Modelo: `bert-base-uncased`  
- `use_fast=False` (evita crash no Python 3.14)  
- truncation ativado  
- `max_length=64`  
- padding din√¢mico com `DataCollatorWithPadding`

### Limpeza do dataset
Ap√≥s tokeniza√ß√£o, foram mantidas apenas as colunas:

- input_ids  
- attention_mask  
- labels  

para evitar erros ao usar o collator din√¢mico.

---

# 6. Configura√ß√£o de Treinamento

### Dispositivo
GPU **MPS** (Metal Performance Shaders) ‚Äì MacBook Air M4.

### Hiperpar√¢metros
- Epochs: **1**  
- Batch size: **8**  
- Otimizador: **AdamW**  
- Learning Rate: **2e-5**  
- Scheduler linear  

### Motiva√ß√£o da configura√ß√£o
A utiliza√ß√£o de subset + 1 √©poca garante:

- execu√ß√£o r√°pida e est√°vel,  
- aus√™ncia de travamentos,  
- reprodutibilidade para entrega parcial.

---

# 7. Resultados do Treinamento Parcial

Sa√≠da da execu√ß√£o:
```bash
Epoch 1/1
Train loss: 0.0670
Val loss: 0.0529
Val F1: 0.7426
```

### Interpreta√ß√£o
- F1 de **0.7426** √© excelente para apenas 1 Epoch com subset.  
- O loss baixo √© esperado pelo desbalanceamento do dataset (maioria dos casos n√£o s√£o t√≥xicos).  
- O modelo demonstra aprendizado consistente.  
- N√£o h√° ind√≠cios de overfitting ou underfitting nesta etapa.

---

# 8. Gr√°ficos

### Loss por Epoch  
![alt text](loss-por-epoch.png)

### F1 Micro por Epoch  
![alt text](f1-micro-por-epoch.png)

---

# 9. Valida√ß√£o Adicional

O modelo foi avaliado manualmente com exemplos reais para garantir coer√™ncia das previs√µes.

```python
samples = [
    "I love this article, very helpful.",
    "You are stupid and disgusting.",
    "I'll find you and hurt you.",
    "Thank you for your support!",
]
```
```bash
Texto: "I love this article, very helpful."
Predi√ß√µes: 
{
    'toxic': 0.005, 
    'severe_toxic': 0.002, 
    'obscene': 0.003, 
    'threat': 0.002, 
    'insult': 0.004, 
    'identity_hate': 0.003
}

Texto: "You are stupid and disgusting."
Predi√ß√µes: 
{
    'toxic': 0.928, 
    'severe_toxic': 0.081, 
    'obscene': 0.636, 
    'threat': 0.041, 
    'insult': 0.641, 
    'identity_hate': 0.109
}

Texto: "I'll find you and hurt you."
Predi√ß√µes: 
{
    'toxic': 0.567, 
    'severe_toxic': 0.023, 
    'obscene': 0.14, 
    'threat': 0.031, 
    'insult': 0.252, 
    'identity_hate': 0.049
}

Texto: "Thank you for your support!"
Predi√ß√µes: 
{
    'toxic': 0.006, 
    'severe_toxic': 0.002, 
    'obscene': 0.003, 
    'threat': 0.002, 
    'insult': 0.004, 
    'identity_hate': 0.003
}
```

# 10. Conclus√£o da Entrega 21/11

Esta etapa inicial foi conclu√≠da com √™xito:

- defini√ß√£o clara da aplica√ß√£o,  
- prepara√ß√£o e subset do dataset,  
- pipeline completo de tokeniza√ß√£o ‚Üí DataLoader ‚Üí treinamento ‚Üí valida√ß√£o,  
- uso da GPU MPS no MacBook Air M4,  
- resultados consistentes e m√©tricas apresentadas,  
- valida√ß√£o adicional confirmando o comportamento do modelo.

O baseline est√° pronto para as pr√≥ximas an√°lises.

---

# 11. Pr√≥ximos Passos ‚Äî Entrega 28/11 (Robustez)

A pr√≥xima etapa incluir√°:

- ru√≠do ortogr√°fico,  
- substitui√ß√£o lexical,  
- inser√ß√£o de emojis,  
- simplifica√ß√£o do texto,  
- perturba√ß√µes adversariais simples.

Ser√° medida a varia√ß√£o do F1 sob cada perturba√ß√£o.

---

# 12. C√≥digo Fonte

Incluso no reposit√≥rio:

- Notebook do treinamento,  
- Script `train_gpu.ipynb`,  
- `requirements.txt`,  
- Modelo salvo em `baseline_model/`.
