# ğŸ“„ RelatÃ³rio da Entrega â€” 05/12
## AnÃ¡lise de Interpretabilidade do Modelo BERT para ClassificaÃ§Ã£o de Toxicidade
### TÃ³picos AvanÃ§ados em Sistemas de InformaÃ§Ã£o (IF1015)

---

Este relatÃ³rio apresenta a avaliaÃ§Ã£o de interpretabilidade de um modelo BERT treinado para classificaÃ§Ã£o multilabel de toxicidade (dataset Jigsaw Toxicity). SÃ£o aplicadas duas tÃ©cnicas de explicabilidade:

- **LIME (Local Interpretable Model-Agnostic Explanations)** â€” explicaÃ§Ãµes locais baseadas em perturbaÃ§Ã£o do texto.  
- **Integrated Gradients (Captum)** â€” explicaÃ§Ãµes baseadas em gradiente sobre as embeddings do modelo.

As tÃ©cnicas permitem entender *quais tokens mais contribuem* para cada prediÃ§Ã£o, verificando se o modelo aprendeu padrÃµes linguÃ­sticos coerentes.

---

# 1. Amostra de texto analisado

O texto selecionado para anÃ¡lise com LIME foi:

> **"You are a disgusting idiot and nobody likes you."**

O texto analisado com Integrated Gradients foi:

> **"I will find you and hurt you badly."**

---

# 2. Explicabilidade com LIME

LIME identifica os tokens que mais influenciam a probabilidade prevista para uma determinada classe. As tabelas abaixo mostram os pesos atribuÃ­dos a cada token â€” valores positivos indicam que o token **aumenta** a probabilidade da classe, e negativos indicam que **reduz**.

---

## 2.1 ExplicaÃ§Ã£o da classe **"insult"**

- idiot -> 0.4289
- disgusting -> 0.1621
- You -> 0.0603
- you -> 0.0368
- and -> -0.0293
- a -> 0.0276
- nobody -> 0.0153
- likes -> -0.0112
- are -> 0.0024


**InterpretaÃ§Ã£o**

- Os tokens mais relevantes para o modelo detectar *insulto* foram **idiot** e **disgusting**, o que demonstra aprendizado adequado de termos ofensivos diretos.
- Pronome **you / You** tambÃ©m aumenta a probabilidade, pois personaliza a agressÃ£o.
- Conectivos como **and**, **likes** apresentam impacto pequeno ou negativo â€” esperado, pois nÃ£o carregam conteÃºdo ofensivo.

Arquivo gerado: **`lime_insult.html`**

---

## 2.2 ExplicaÃ§Ã£o da classe **"toxic"**

- idiot -> 0.3505
- disgusting -> 0.2075
- You -> 0.0483
- nobody -> 0.0384
- you -> 0.0355
- a -> 0.0266
- and -> -0.0222
- are -> 0.0154
- likes -> -0.0009


**InterpretaÃ§Ã£o**

- Novamente, **idiot** e **disgusting** dominam como indicadores de toxicidade geral.
- Tokens **You**, **you**, **nobody** contribuem positivamente por estarem associados a ataques pessoais ou linguagem depreciativa.
- Palavras funcionais tÃªm impacto desprezÃ­vel ou negativo, o que indica boa separaÃ§Ã£o semÃ¢ntica aprendida pelo modelo.

---

# 3. Explicabilidade com Integrated Gradients (Captum)

Integrated Gradients mede a contribuiÃ§Ã£o de cada token calculando o gradiente entre um baseline neutro e a entrada real. Aqui, as explicaÃ§Ãµes foram feitas diretamente sobre as **embeddings** do BERT, garantindo derivabilidade.

### Texto analisado:
> **"I will find you and hurt you badly."**

---

## 3.1 ImportÃ¢ncia dos tokens (IG)

- [CLS] -> -0.0686
- i -> 0.1119
- will -> 0.2118
- find -> 0.1446
- you -> 0.5793
- and -> -0.1841
- hurt -> 0.3828
- you -> 0.7625
- badly -> 0.0416
- . -> -0.0319
- [SEP] -> 0.2951


**InterpretaÃ§Ã£o**

- O modelo identifica corretamente que **"you"**, **"hurt"**, e **"you" (segunda ocorrÃªncia)** sÃ£o os tokens *mais importantes* para detectar ameaÃ§a (*threat*).
- Verbos de intenÃ§Ã£o (**will**, **find**) tambÃ©m tÃªm forte contribuiÃ§Ã£o.
- Tokens estruturais (**[CLS]**, **[SEP]**, **.**) apresentam influÃªncia baixa ou moderada â€” comportamento normal em modelos BERT.
- O token **"and"** possui peso negativo, sugerindo que o conector suaviza a agressÃ£o quando considerado isoladamente.

---

# 4. ConclusÃµes

A anÃ¡lise de interpretabilidade mostra que:

- O modelo **aprendeu padrÃµes semÃ¢nticos coerentes** com toxicidade e insulto.  
- Palavras ofensivas receberam altos pesos em LIME (idiot, disgusting).  
- Tokens relacionados a ameaÃ§a receberam altos pesos no IG (hurt, you, will).  
- Palavras funcionais exibiram pouca influÃªncia, indicando que o modelo nÃ£o estÃ¡ enviesado por estrutura gramatical.  
- O comportamento do modelo Ã© consistente e interpretÃ¡vel, apoiando sua confiabilidade para uso acadÃªmico e experimental.
